# Learning to Finetune LLM using LoRA with MLX

I am making this repository to document how I fine-tuned mistralai/Mistral-7B-Instruct-v0.2 model using LoRA technique and MLX framework on a MacBook Pro 2021 M1 Pro.

I followed the tutorial from [here](https://apeatling.com/articles/part-1-setting-up-your-environment/) and the references from [MLX examples](https://github.com/ml-explore/mlx-examples) repository.
